import os
import requests
from dotenv import load_dotenv

load_dotenv()

# üîê Cl√© Groq
GROQ_API_KEY = os.getenv("GROQ_API_KEY")
if not GROQ_API_KEY:
    raise ValueError("GROQ_API_KEY non trouv√©e dans .env")

# URL OpenAI Compatible de Groq
BASE_URL = "https://api.groq.com/openai/v1/chat/completions"

# Mod√®le Groq √† utiliser
MODEL = "mixtral-8x7b-32768"  # exemple de mod√®le performant :contentReference[oaicite:4]{index=4}

# Contexte officiel DAFANI
DAFANI_CONTEXT = """
Tu es un assistant officiel qui r√©pond uniquement sur l‚Äôentreprise DAFANI S.A.

INFORMATIONS DAFANI :
- Secteur : Industrie agroalimentaire
- Activit√© : Transformation de fruits tropicaux en jus et nectars
- Produits : Nectar mangue, nectar orange, cocktails mangue-orange, mangue-ananas-passion
- Formats : 0,5 L et 1 L
- Localisation : Orodara, Burkina Faso
- T√©l√©phone : (+226) 20 99 53 53
- Email : dafani2006@yahoo.fr
- Site web : www.dafani.net
- Cr√©ation : 22 juin 2007

R√àGLES :
- R√©ponds uniquement avec ces informations
- N‚Äôinvente rien
- Si l‚Äôinformation n‚Äôexiste pas, dis : "Information non disponible chez Dafani"
"""

def ask_dafani_groq(question: str) -> str:
    prompt = f"{DAFANI_CONTEXT}\n\nQUESTION : {question}"

    headers = {
        "Authorization": f"Bearer {GROQ_API_KEY}",
        "Content-Type": "application/json"
    }

    data = {
        "model": MODEL,
        "messages": [
            {"role": "system", "content": "Tu es un assistant utile."},
            {"role": "user", "content": prompt}
        ],
        "temperature": 0.7
    }

    response = requests.post(BASE_URL, json=data, headers=headers)
    response.raise_for_status()

    # R√©cup√®re la r√©ponse texte
    result = response.json()
    # La structure est compatible OpenAI ‚Üí on prend choices[0].message.content
    return result["choices"][0]["message"]["content"]
